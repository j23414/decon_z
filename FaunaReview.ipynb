{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7246920b-4ac5-45ff-91fd-5522c95aed6b",
   "metadata": {},
   "source": [
    "# Fauna\n",
    "\n",
    "This is a deconstruction of parts of fauna. \n",
    "\n",
    "* https://github.com/nextstrain/fauna\n",
    "\n",
    "Scripts:\n",
    "\n",
    "**zika_upload.py**\n",
    "\n",
    "```\n",
    "python3 vdb/zika_upload.py \\\n",
    "  -db vdb \\\n",
    "  -v zika \\\n",
    "  --source genbank \\\n",
    "  --locus genome \\\n",
    "  --fname GenomicFastaResults.fasta\n",
    "```\n",
    "\n",
    "**zika_update.py**\n",
    "\n",
    "```\n",
    "python3 vdb/zika_update.py \\\n",
    "  -db vdb \\\n",
    "  -v zika \\\n",
    "  --update_citations\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b5a191-20a9-4446-adbd-2ccb76e6335e",
   "metadata": {},
   "source": [
    "*check dependencies listed in requirements.txt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f3cb59-e085-4d59-af0a-4c66aedd8b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages available\n"
     ]
    }
   ],
   "source": [
    "import Bio            # biopython\n",
    "import boto\n",
    "import pandas\n",
    "import rethinkdb\n",
    "import requests\n",
    "import unidecode\n",
    "import xlrd\n",
    "print(\"Packages available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf81d2fb-ff3d-4509-9a69-a59566f60b24",
   "metadata": {},
   "source": [
    "## 1. Load an example dataset\n",
    "\n",
    "Practice on 10 zika sequences. Pull from:\n",
    "\n",
    "* https://www.viprbrc.org/brc/vipr_genome_search.spg?method=ShowCleanSearch&decorator=flavi_zika"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25f90c8-e349-4c03-9db2-580062d4c1d1",
   "metadata": {},
   "source": [
    "## 2. Process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8895643-63f6-4de7-9c63-403a1478a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "strain_fix_fname =  \"fauna/source-data/zika_strain_name_fix.tsv\"\n",
    "location_fix_fname = \"fauna/source-data/zika_location_fix.tsv\"\n",
    "date_fix_fname = \"fauna/source-data/zika_date_fix.tsv\"\n",
    "\n",
    "virus_fasta_fields = {1:'strain', 3:'collection_date', 4: 'host', 5:'country'}\n",
    "sequence_fasta_fields = {0:'accession', 1:'strain'}\n",
    "\n",
    "# Args\n",
    "db = \"vdb\"\n",
    "v = \"zika\"\n",
    "source = \"genbank\"\n",
    "locus = \"genome\"\n",
    "fname = \"GenomicFastaResults.fasta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa13f2d3-185a-4c4a-9371-e7f533c54019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Packages\n",
    "import os, re, time, datetime, csv, sys\n",
    "from rethinkdb import r\n",
    "from Bio import SeqIO\n",
    "#from upload import upload # vdb/upload.py; vdb/parse.py\n",
    "#from upload import get_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a866a61b-6709-4c67-9099-d21c71bcd1e4",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e76521e6-ab23-4d63-8e0e-b73b4e4163ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRI/PRVABC59/2015', 'PRVABC_59', 'Ae-aegypti-FL01M', 'Ae-aegypti-FL02M', 'Ae-aegypti-FL03M', 'Ae-aegypti-FL04M', 'Ae-aegypti-FL05M', 'Ae-aegypti-FL06M', 'Ae-aegypti_FL08M', 'FL001Sa']\n"
     ]
    }
   ],
   "source": [
    "# upload.py\n",
    "def replace_strain_name(original_name, fixes={}):\n",
    "    '''\n",
    "    return the new strain name that will replace the original\n",
    "    '''\n",
    "    if original_name in fixes:\n",
    "        return fixes[original_name] \n",
    "    else:\n",
    "        return original_name #JC\n",
    "\n",
    "# ...\n",
    "def define_strain_fixes(fname):\n",
    "    '''\n",
    "    Open strain name fixing files and define corresponding dictionaries\n",
    "    '''\n",
    "    reader = csv.DictReader(filter(lambda row: row[0]!='#', open(fname)), delimiter='\\t')\n",
    "    fix_whole_name = {}\n",
    "    for line in reader:\n",
    "        fix_whole_name[line['label'].encode().decode('unicode-escape')] = line['fix']\n",
    "    return fix_whole_name             # fixes[original_name]\n",
    "# ...\n",
    "fix_whole_name = define_strain_fixes(strain_fix_fname)  # tsv file in Input\n",
    "type(fix_whole_name)\n",
    "print(list(fix_whole_name)[:10])\n",
    "\n",
    "# ... do same for locations\n",
    "# self.fix_location = self.define_location_fixes(self.location_fix_fname) # tsv file in input\n",
    "# self.fix_date = self.define_date_fixes(self.date_fix_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ebefd42-1931-46fb-bdd6-7df2be1e5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zika_upload.py\n",
    "def fix_name(name): # polymorphism, overwrite fix_names in upload.py\n",
    "    original_name = name\n",
    "    name = replace_strain_name(original_name, fix_whole_name) \n",
    "    name = name.replace('Zika_virus', '').replace('Zikavirus', '').replace('Zika virus', '').replace('Zika', '').replace('ZIKV', '')\n",
    "    name = name.replace('Human', '').replace('human', '').replace('H.sapiens_wt', '').replace('H.sapiens_tc', '').replace('Hsapiens_tc', '').replace('H.sapiens-tc', '').replace('Homo_sapiens', '').replace('Homo sapiens', '').replace('Hsapiens', '').replace('H.sapiens', '')\n",
    "    name = name.replace('/Hu/', '')\n",
    "    name = name.replace('_Asian', '').replace('_Asia', '').replace('_asian', '').replace('_asia', '')\n",
    "    name = name.replace('_URI', '').replace('_SER', '').replace('_PLA', '').replace('_MOS', '').replace('_SAL', '')\n",
    "    name = name.replace('Aaegypti_wt', 'Aedes_aegypti').replace('Aedessp', 'Aedes_sp')\n",
    "    name = name.replace(' ', '').replace('\\'', '').replace('(', '').replace(')', '').replace('//', '/').replace('__', '_').replace('.', '').replace(',', '')\n",
    "    name = re.sub('^[\\/\\_\\-]', '', name)\n",
    "    try:\n",
    "        name = 'V' + str(int(name))  # Deal with numbers?\n",
    "    except:\n",
    "        pass\n",
    "    name = replace_strain_name(name, fix_whole_name)    # Before and after local processing? Kay...\n",
    "    return name, original_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bb2d46-4c32-4b29-90f1-c261c8691632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_casing(self, document): # JC\n",
    "    for field in ['host']:\n",
    "        if field in document and document[field] is not None:\n",
    "            document[field] = self.camelcase_to_snakecase(document[field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58446807-3a29-4921-bba0-f3b72ecb4051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'strain': 'ZIKV_SG_072', 'collection_date': '2016_08_28', 'host': 'Human', 'country': 'Singapore'}, {'strain': 'Mexico_Rus_12TVR_2017', 'collection_date': '2017_01_30', 'host': 'Human', 'country': 'Russia'}, {'strain': 'Dominican_Rep_Rus_7EGR_2016', 'collection_date': '2016_08_25', 'host': 'Human', 'country': 'Russia'}, {'strain': 'Mexico_Rus_10GNN_2016', 'collection_date': '2016_11_09', 'host': 'Human', 'country': 'Russia'}, {'strain': 'Saint_Barthelemi_Rus_6BRN_2016', 'collection_date': '2016_07_25', 'host': 'Human', 'country': 'Russia'}, {'strain': 'Dominican_Rep_Rus_5RMN_2016', 'collection_date': '2016_05_31', 'host': 'Human', 'country': 'Russia'}, {'strain': 'Dominican_Rep_Rus_8ZBR_2016', 'collection_date': '2016_08_25', 'host': 'Human', 'country': 'Russia'}, {'strain': 'SY01_2016', 'collection_date': '2016_11_01', 'host': 'Human', 'country': 'China'}, {'strain': 'SK403/13AS', 'collection_date': '2013_09_21', 'host': 'Human', 'country': 'Thailand'}, {'strain': 'SK364/13AS', 'collection_date': '2013_07_09', 'host': 'Human', 'country': 'Thailand'}]\n",
      "\n",
      "\n",
      "strain:  ZIKV_SG_072\n",
      "fix_name output: ('SG_072', 'ZIKV_SG_072')\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "def parse_fasta_file(fasta, virus_fasta_fields, sequence_fasta_fields, **kwargs):\n",
    "    '''\n",
    "    Parse FASTA file with default header formatting\n",
    "    :return: list of documents(dictionaries of attributes) to upload\n",
    "    '''\n",
    "    header_fixes = False\n",
    "    if (kwargs[\"fasta_header_fix\"]):\n",
    "        header_fixes = {}\n",
    "        try:\n",
    "            with open(kwargs[\"fasta_header_fix\"], 'rU') as fh:\n",
    "                for line in fh:\n",
    "                    if not line.startswith('#'):\n",
    "                        k, v = line.strip().split(\"\\t\")\n",
    "                        header_fixes[k] = v                \n",
    "        except IOError:\n",
    "            raise Exception(kwargs[\"fasta_header_fix\"], \"not found\")\n",
    "    viruses = []\n",
    "    sequences = []\n",
    "    try:\n",
    "        handle = open(fasta, 'r')\n",
    "    except IOError:\n",
    "        raise Exception(fasta, \"not found\")\n",
    "    else:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            if header_fixes:\n",
    "                try:\n",
    "                    record.description = header_fixes[record.description]\n",
    "                except KeyError:\n",
    "                    raise Exception(record.description, \"not in header fix file. Fatal.\")\n",
    "            content = list(map(lambda x: x.strip(), record.description.replace(\">\", \"\").split('|')))\n",
    "            v = {key: content[ii] if ii < len(content) else \"\" for ii, key in virus_fasta_fields.items()}\n",
    "            s = {key: content[ii] if ii < len(content) else \"\" for ii, key in sequence_fasta_fields.items()}\n",
    "            s['sequence'] = str(record.seq).lower()\n",
    "            #v = self.add_virus_fields(v, **kwargs)\n",
    "            #s = self.add_sequence_fields(s, **kwargs)\n",
    "            sequences.append(s)\n",
    "            viruses.append(v)\n",
    "        handle.close()\n",
    "    return (viruses, sequences)\n",
    "\n",
    "zika_seqs = \"data/small.fasta\"\n",
    "\n",
    "zika_fasta = parse_fasta_file(zika_seqs, virus_fasta_fields, sequence_fasta_fields, fasta_header_fix = False)\n",
    "\n",
    "print(zika_fasta[0])\n",
    "\n",
    "print(\"\\n\\nstrain: \",zika_fasta[0][0]['strain'])\n",
    "\n",
    "print(\"fix_name output:\", fix_name(zika_fasta[0][0]['strain']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414b013c-6fbc-4014-9aa7-629060d5de64",
   "metadata": {},
   "source": [
    "## 3. Upload to fauna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e018610f-2937-4341-ba9f-14fd4d96e51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54c302-3b6d-40d3-8256-91db8419fb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f797c-ca46-45eb-96df-3f96dcbad926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyterlab] *",
   "language": "python",
   "name": "conda-env-jupyterlab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
