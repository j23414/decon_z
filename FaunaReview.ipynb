{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7246920b-4ac5-45ff-91fd-5522c95aed6b",
   "metadata": {},
   "source": [
    "# Fauna\n",
    "\n",
    "This is a deconstruction of parts of fauna. \n",
    "\n",
    "* https://github.com/nextstrain/fauna\n",
    "\n",
    "Scripts:\n",
    "\n",
    "**zika_upload.py**\n",
    "\n",
    "```\n",
    "python3 vdb/zika_upload.py \\\n",
    "  -db vdb \\\n",
    "  -v zika \\\n",
    "  --source genbank \\\n",
    "  --locus genome \\\n",
    "  --fname GenomicFastaResults.fasta\n",
    "```\n",
    "\n",
    "**zika_update.py**\n",
    "\n",
    "```\n",
    "python3 vdb/zika_update.py \\\n",
    "  -db vdb \\\n",
    "  -v zika \\\n",
    "  --update_citations\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b5a191-20a9-4446-adbd-2ccb76e6335e",
   "metadata": {},
   "source": [
    "*check dependencies listed in requirements.txt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f3cb59-e085-4d59-af0a-4c66aedd8b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages available\n"
     ]
    }
   ],
   "source": [
    "# ==== Packages\n",
    "import os, re, time, datetime, csv, sys\n",
    "from Bio import SeqIO\n",
    "from typing import NamedTuple\n",
    "print(\"Packages available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf81d2fb-ff3d-4509-9a69-a59566f60b24",
   "metadata": {},
   "source": [
    "## 1. Load an example dataset\n",
    "\n",
    "Practice on 10 zika sequences. Pull from:\n",
    "\n",
    "* https://www.viprbrc.org/brc/vipr_genome_search.spg?method=ShowCleanSearch&decorator=flavi_zika"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25f90c8-e349-4c03-9db2-580062d4c1d1",
   "metadata": {},
   "source": [
    "## 2. Process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8895643-63f6-4de7-9c63-403a1478a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Input variables\n",
    "zika_seqs = \"../example_data/small.fasta\"\n",
    "\n",
    "# From fauna\n",
    "strain_fix_fname =  \"zika_strain_name_fix.tsv\"\n",
    "location_fix_fname = \"zika_location_fix.tsv\"\n",
    "date_fix_fname = \"zika_date_fix.tsv\"\n",
    "\n",
    "virus_fasta_fields = {1:'strain', 3:'collection_date', 4: 'host', 5:'country'}\n",
    "sequence_fasta_fields = {0:'accession', 1:'strain'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a866a61b-6709-4c67-9099-d21c71bcd1e4",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e76521e6-ab23-4d63-8e0e-b73b4e4163ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vdl/uploads.py\n",
    "def define_fixes_dict(fname:str) -> dict[str,str]:\n",
    "    '''\n",
    "    Open strain/location/date fixing tsv files and define corresponding dictionaries\n",
    "    '''\n",
    "    reader = csv.DictReader(filter(lambda row: row[0]!='#', open(fname)), delimiter='\\t')\n",
    "    fixes_dict = {}\n",
    "    for line in reader:\n",
    "        fixes_dict[line['label'].encode().decode('unicode-escape')] = line['fix']\n",
    "    return fixes_dict\n",
    "\n",
    "def fixes_str(original_str:str, fixes_dict:dict[str,str]={}):\n",
    "    '''\n",
    "    return the new strain name/location/date that will replace the original string\n",
    "    '''\n",
    "    if original_str in fixes_dict:\n",
    "        return fixes[original_str] \n",
    "    else:\n",
    "        return original_str\n",
    "\n",
    "# vdl/zika_uploads.py\n",
    "def fixes_strain_name(name, fixes_tsv:str=\"\") -> (str,str): # Since we can't decide if we want strain or name\n",
    "    fixes_dict = {}\n",
    "    if(len(fixes_tsv)>0):\n",
    "        fixes_dict = define_fixes_dict(fixes_tsv)\n",
    "    \n",
    "    original_name = name\n",
    "    name = fixes_str(original_name, fixes_dict) \n",
    "    name = name.replace('Zika_virus', '').replace('Zikavirus', '').replace('Zika virus', '').replace('Zika', '').replace('ZIKV', '')\n",
    "    name = name.replace('Human', '').replace('human', '').replace('H.sapiens_wt', '').replace('H.sapiens_tc', '').replace('Hsapiens_tc', '').replace('H.sapiens-tc', '').replace('Homo_sapiens', '').replace('Homo sapiens', '').replace('Hsapiens', '').replace('H.sapiens', '')\n",
    "    name = name.replace('/Hu/', '')\n",
    "    name = name.replace('_Asian', '').replace('_Asia', '').replace('_asian', '').replace('_asia', '')\n",
    "    name = name.replace('_URI', '').replace('_SER', '').replace('_PLA', '').replace('_MOS', '').replace('_SAL', '')\n",
    "    name = name.replace('Aaegypti_wt', 'Aedes_aegypti').replace('Aedessp', 'Aedes_sp')\n",
    "    name = name.replace(' ', '').replace('\\'', '').replace('(', '').replace(')', '').replace('//', '/').replace('__', '_').replace('.', '').replace(',', '')\n",
    "    name = re.sub('^[\\/\\_\\-]', '', name)\n",
    "    try: # ID must start with letter\n",
    "        name = 'V' + str(int(name))\n",
    "    except:\n",
    "        pass\n",
    "    name = fixes_str(name, fixes_dict)\n",
    "    return name, original_name\n",
    "\n",
    "# vdl/parse.py Load data\n",
    "def parse_fasta_file(fasta, virus_fasta_fields, sequence_fasta_fields, **kwargs):\n",
    "    '''\n",
    "    Parse FASTA file with default header formatting\n",
    "    :return: list of documents(dictionaries of attributes) to upload\n",
    "    '''\n",
    "    header_fixes = False\n",
    "    if (kwargs[\"fasta_header_fix\"]):\n",
    "        header_fixes = {}\n",
    "        try:\n",
    "            with open(kwargs[\"fasta_header_fix\"], 'rU') as fh:\n",
    "                for line in fh:\n",
    "                    if not line.startswith('#'):\n",
    "                        k, v = line.strip().split(\"\\t\")\n",
    "                        header_fixes[k] = v                \n",
    "        except IOError:\n",
    "            raise Exception(kwargs[\"fasta_header_fix\"], \"not found\")\n",
    "    viruses = []\n",
    "    sequences = []\n",
    "    try:\n",
    "        handle = open(fasta, 'r')\n",
    "    except IOError:\n",
    "        raise Exception(fasta, \"not found\")\n",
    "    else:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            if header_fixes:\n",
    "                try:\n",
    "                    record.description = header_fixes[record.description]\n",
    "                except KeyError:\n",
    "                    raise Exception(record.description, \"not in header fix file. Fatal.\")\n",
    "            content = list(map(lambda x: x.strip(), record.description.replace(\">\", \"\").split('|')))\n",
    "            v = {key: content[ii] if ii < len(content) else \"\" for ii, key in virus_fasta_fields.items()}\n",
    "            s = {key: content[ii] if ii < len(content) else \"\" for ii, key in sequence_fasta_fields.items()}\n",
    "            s['sequence'] = str(record.seq).lower()\n",
    "            #v = self.add_virus_fields(v, **kwargs)\n",
    "            #s = self.add_sequence_fields(s, **kwargs)\n",
    "            sequences.append(s)\n",
    "            viruses.append(v)\n",
    "        handle.close()\n",
    "    return (viruses, sequences)\n",
    "\n",
    "# === Only fix casing on the Host?\n",
    "def fix_casing(self, document): # JC\n",
    "    for field in ['host']:\n",
    "        if field in document and document[field] is not None:\n",
    "            document[field] = self.camelcase_to_snakecase(document[field])\n",
    "\n",
    "# ===== Main Method\n",
    "fix_name_dict = define_fixes_dict(strain_fix_fname)  # tsv file in Input\n",
    "fix_location_dict = define_fixes_dict(location_fix_fname)\n",
    "fix_date_dict = define_fixes_dict(date_fix_fname)\n",
    "\n",
    "type(fix_name_dict)\n",
    "type(fix_location_dict)\n",
    "type(fix_date_dict)\n",
    "\n",
    "# ... do same for locations\n",
    "# self.fix_location = self.define_location_fixes(self.location_fix_fname) # tsv file in input\n",
    "# self.fix_date = self.define_date_fixes(self.date_fix_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58446807-3a29-4921-bba0-f3b72ecb4051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'strain': 'ZIKV_SG_072', 'collection_date': '2016_08_28', 'host': 'Human', 'country': 'Singapore'}, {'strain': 'Mexico_Rus_12TVR_2017', 'collection_date': '2017_01_30', 'host': 'Human', 'country': 'Russia'}, {'strain': 'Dominican_Rep_Rus_7EGR_2016', 'collection_date': '2016_08_25', 'host': 'Human', 'country': 'Russia'}, {'strain': 'Mexico_Rus_10GNN_2016', 'collection_date': '2016_11_09', 'host': 'Human', 'country': 'Russia'}, {'strain': 'Saint_Barthelemi_Rus_6BRN_2016', 'collection_date': '2016_07_25', 'host': 'Human', 'country': 'Russia'}, {'strain': 'Dominican_Rep_Rus_5RMN_2016', 'collection_date': '2016_05_31', 'host': 'Human', 'country': 'Russia'}, {'strain': 'Dominican_Rep_Rus_8ZBR_2016', 'collection_date': '2016_08_25', 'host': 'Human', 'country': 'Russia'}, {'strain': 'SY01_2016', 'collection_date': '2016_11_01', 'host': 'Human', 'country': 'China'}, {'strain': 'SK403/13AS', 'collection_date': '2013_09_21', 'host': 'Human', 'country': 'Thailand'}, {'strain': 'SK364/13AS', 'collection_date': '2013_07_09', 'host': 'Human', 'country': 'Thailand'}]\n",
      "\n",
      "\n",
      "strain:  ZIKV_SG_072\n",
      "fix_strain_name output: ('SG_072', 'ZIKV_SG_072')\n"
     ]
    }
   ],
   "source": [
    "zika_fasta = \"../example_data/small.fasta\"\n",
    "\n",
    "zika_seqs = parse_fasta_file(zika_seqs, virus_fasta_fields, sequence_fasta_fields, fasta_header_fix = False)\n",
    "\n",
    "print(zika_seqs[0])\n",
    "print(\"\\n\\nstrain: \",zika_seqs[0][0]['strain'])\n",
    "print(\"fix_strain_name output:\", fixes_strain_name(zika_seqs[0][0]['strain']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414b013c-6fbc-4014-9aa7-629060d5de64",
   "metadata": {},
   "source": [
    "## 3. Upload to fauna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e018610f-2937-4341-ba9f-14fd4d96e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54c302-3b6d-40d3-8256-91db8419fb4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f797c-ca46-45eb-96df-3f96dcbad926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyterlab] *",
   "language": "python",
   "name": "conda-env-jupyterlab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
